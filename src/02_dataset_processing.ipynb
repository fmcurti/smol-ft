{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9404d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total splits: {len(dataset_dict)}\")\n",
    "print(f\"Available splits: {list(dataset_dict.keys())}\")\n",
    "print(f\"Number of total rows: {sum([dataset_dict[d].num_rows for d in dataset_dict])}\")\n",
    "print(f\"Dataset structure: {dataset_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "647e9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196af01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPLORING SMOLTALK2 DATASET ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and explore the SmolTalk2 dataset\n",
    "print(\"=== EXPLORING SMOLTALK2 DATASET ===\\n\")\n",
    "\n",
    "# Load the SFT subset\n",
    "dataset_dict = load_dataset_builder(\"HuggingFaceTB/smoltalk2\", \"SFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b11215af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total splits: 25\n",
      "Available splits: ['LongAlign_64k_Qwen3_32B_yarn_131k_think', 'OpenThoughts3_1.2M_think', 'aya_dataset_Qwen3_32B_think', 'multi_turn_reasoning_if_think', 's1k_1.1_think', 'smolagents_toolcalling_traces_think', 'smoltalk_multilingual8_Qwen3_32B_think', 'smoltalk_systemchats_Qwen3_32B_think', 'table_gpt_Qwen3_32B_think', 'LongAlign_64k_context_lang_annotated_lang_6_no_think', 'Mixture_of_Thoughts_science_no_think', 'OpenHermes_2.5_no_think', 'OpenThoughts3_1.2M_no_think_no_think', 'hermes_function_calling_v1_no_think', 'smoltalk_multilingual_8languages_lang_5_no_think', 'smoltalk_smollm3_everyday_conversations_no_think', 'smoltalk_smollm3_explore_instruct_rewriting_no_think', 'smoltalk_smollm3_smol_magpie_ultra_no_think', 'smoltalk_smollm3_smol_rewrite_no_think', 'smoltalk_smollm3_smol_summarize_no_think', 'smoltalk_smollm3_systemchats_30k_no_think', 'table_gpt_no_think', 'tulu_3_sft_personas_instruction_following_no_think', 'xlam_traces_no_think', 'smoltalk_everyday_convs_reasoning_Qwen3_32B_think']\n",
      "Number of total rows: 3383242\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Total splits: {len(dataset_dict.info.splits)}\")\n",
    "print(f\"Available splits: {list(dataset_dict.info.splits.keys())}\")\n",
    "print(f\"Number of total rows: {sum([dataset_dict.info.splits[d].num_examples for d in dataset_dict.info.splits])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e44ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROCESSING GSM8K DATASET ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 27445.58 examples/s]\n",
      "Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 171666.21 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original GSM8K example: {'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 2997.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed example: {'messages': [{'content': 'You are a math tutor. Solve problems step by step.', 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}, {'content': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72', 'role': 'assistant'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to process different dataset formats\n",
    "def process_qa_dataset(examples, question_col, answer_col):\n",
    "    \"\"\"Process Q&A datasets into chat format\"\"\"\n",
    "    processed = []\n",
    "    \n",
    "    for question, answer in zip(examples[question_col], examples[answer_col]):\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "        processed.append(messages)\n",
    "    \n",
    "    return {\"messages\": processed}\n",
    "\n",
    "def process_instruction_dataset(examples):\n",
    "    \"\"\"Process instruction-following datasets\"\"\"\n",
    "    processed = []\n",
    "    \n",
    "    for instruction, response in zip(examples[\"instruction\"], examples[\"response\"]):\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": instruction},\n",
    "            {\"role\": \"assistant\", \"content\": response}\n",
    "        ]\n",
    "        processed.append(messages)\n",
    "    \n",
    "    return {\"messages\": processed}\n",
    "\n",
    "# Example: Process GSM8K math dataset\n",
    "print(\"=== PROCESSING GSM8K DATASET ===\\n\")\n",
    "\n",
    "gsm8k = load_dataset(\"openai/gsm8k\", \"main\", split=\"train[:100]\")  # Small subset for demo\n",
    "print(f\"Original GSM8K example: {gsm8k[0]}\")\n",
    "\n",
    "# Convert to chat format\n",
    "def process_gsm8k(examples):\n",
    "    processed = []\n",
    "    for question, answer in zip(examples[\"question\"], examples[\"answer\"]):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a math tutor. Solve problems step by step.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "        processed.append(messages)\n",
    "    return {\"messages\": processed}\n",
    "\n",
    "gsm8k_processed = gsm8k.map(process_gsm8k, batched=True, remove_columns=gsm8k.column_names)\n",
    "print(f\"Processed example: {gsm8k_processed[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb47b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "instruct_model_name = \"HuggingFaceTB/SmolLM3-3B\"\n",
    "\n",
    "# Load tokenizers\n",
    "instruct_tokenizer = AutoTokenizer.from_pretrained(instruct_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd6086e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1272.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FORMATTED TRAINING DATA ===\n",
      "<|im_start|>system\n",
      "## Metadata\n",
      "\n",
      "Knowledge Cutoff Date: June 2025\n",
      "Today Date: 09 November 2025\n",
      "Reasoning Mode: /think\n",
      "\n",
      "## Custom Instructions\n",
      "\n",
      "You are a math tutor. Solve problems step by step.\n",
      "\n",
      "<|im_start|>user\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72<|im_end|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to apply chat templates to processed datasets\n",
    "def apply_chat_template_to_dataset(dataset, tokenizer):\n",
    "    \"\"\"Apply chat template to dataset for training\"\"\"\n",
    "    \n",
    "    def format_messages(examples):\n",
    "        formatted_texts = []\n",
    "        \n",
    "        for messages in examples[\"messages\"]:\n",
    "            # Apply chat template\n",
    "            formatted_text = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=False  # We want the complete conversation\n",
    "            )\n",
    "            formatted_texts.append(formatted_text)\n",
    "        \n",
    "        return {\"text\": formatted_texts}\n",
    "    \n",
    "    return dataset.map(format_messages, batched=True)\n",
    "\n",
    "# Apply to our processed GSM8K dataset\n",
    "gsm8k_formatted = apply_chat_template_to_dataset(gsm8k_processed, instruct_tokenizer)\n",
    "print(\"=== FORMATTED TRAINING DATA ===\")\n",
    "print(gsm8k_formatted[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77310d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smolcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
